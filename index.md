---
layout: default
title: Sarayu Sivakumar Dhaya


---

# Sarayu Sivakumar Dhaya 
### MS in Artificial Intelligence (Dec 2025) | 5+ Years Software Engineering Experience  

AI/ML Engineer building **Deep Learning and Generative AI systems**, with expertise in Reinforcement Learning, Multimodal Retrieval (RAG), and end-to-end AI model development.

---

## About Me

I am a Masterâ€™s graduate in Artificial Intelligence at the University at Buffalo with 5+ years of professional software engineering experience across backend systems and distributed architectures.

My focus is on building **applied AI systems** using Deep Learning architectures, Reinforcement Learning, and Large Language Models (LLMs). I specialize in developing scalable ML pipelines, multimodal retrieval systems, and production-ready AI solutions for real-world impact.

---

## Technical Skills

**Programming:** Python Â· Java Â· SQL  

**Deep Learning & AI:**  
PyTorch Â· TensorFlow Â· Scikit-learn Â· Self-Supervised Learning Â· Reinforcement Learning (PPO, SAC, A2C) Â· Computer Vision Â· NLP Â· Pydantic

**LLMs & Generative AI:**  
RAG Â· ReAct Agents Â· Prompt Engineering Â· OpenCLIP Â· ChromaDB Â· LangChain Â· OpenAI API  

**Data & Systems:**  
Pandas Â· NumPy Â· OpenCV Â· Gymnasium Â· PySpark Â· Hadoop  

**Systems & Deployment:**  
Docker Â· Kubernetes Â· CI/CD Â· GPU-based Training & Inference Â· CUDA  


---
## Project Experience

## Deep Learning-Based Predictive Maintenance of Rotating Machinery  
*(University - Industry Collaboration)*  

- Engineered a triaxial vibration data acquisition pipeline on a custom rotor test rig, generating **100K+ vibration signals** across multiple fault conditions.  
- Developed a custom **dual-encoder 1D CNN** combining time-domain waveforms with FFT-based frequency features using channel-wise attention mechanisms.  
- Implemented multi-window signal processing to capture fault progression trends and reduce sensitivity to transient noise.  
- Applied **contrastive self-supervised pretraining**, achieving **91% downstream classification accuracy** while reducing labeled data dependence.  

**Tech:** PyTorch Â· Signal Processing Â· Self-Supervised Learning Â· CNN Architectures Â· Attention  

---

## Agentic Multimodal RAG with Hybrid Retrieval  
**[ðŸ”— View Source Code](https://github.com/sarayusd/Agentic-Multimodal-RAG-with-Hybrid-Retrieval.git)**

- Built an **agentic multimodal Retrieval-Augmented Generation system** using OpenCLIP, LangChain, ChromaDB, and OpenAI API, indexing **8K+ image-text pairs**.  
- Achieved **84.5% Recall@5 and 0.81 MRR** in text-to-image retrieval evaluation.  
- Architected a ReAct-based LLM agent with tool-driven retrieval and grounded reasoning, achieving **9.06/10 faithfulness** and 3.3% refusal rate.  
- Designed a hybrid ranking pipeline combining dense embeddings with lexical re-scoring to reduce semantic drift and improve grounding robustness.  

**Tech:** OpenCLIP Â· LangChain Â· ChromaDB Â· LLM Agents Â· Hybrid Retrieval  

---

### Sustainable Energy Management in Smart Homes with Reinforcement Learning  
**[ðŸ”— View Source Code](https://github.com/sarayusd/Sustainable-Energy-Management-with-Reinforcement-Learning.git)**

- Explored intelligent battery storage control in CityLearn environment to minimize energy cost and carbon emissions.  
- Implemented and compared **Rule Based Control**, **PPO**, and **SAC** agents.  
- **SAC** achieved best energy efficiency and lowest peak demand.  
- **Tech:** PyTorch Â· CityLearn Â· RL Â· Python  

---

### Scene Recognition with Deep CNNs (MIT Indoor67)  
**[ðŸ”— View Source Code](https://github.com/sarayusd/Scene-Recognition-with-Deep-CNNs)**

**1. Dense like Teacher (Strong Backbone)**  
- Implemented a custom DenseNet-like architecture from scratch.  
- Used **SE (Squeeze and Excitation)** in bottleneck blocks to improve channelwise attention.  

**2. Hybrid CNN + SE (Student) with Knowledge Distillation**  
- Built a lighter Hybrid CNN with SE blocks for faster inference.  
- Distilled soft targets from the Dense-like teacher so that the student learned richer class boundaries than from hard labels alone.  

**3. Ensemble Learning**  
- Final predictions were ensembled across all trained models:  
  - Dense-like teacher  
  - Distilled Hybrid CNN + SE  
  - Other experimental CNN variants (Mini / Efficient-style)  
- Achieved a project-high **76% F1-score** and enhanced robustness by combining multiple models using soft and weighted ensemble voting.  

- **Tech:** PyTorch Â· CNN Â· SE blocks Â· Knowledge distillation Â· Ensemble voting
  
---

##  Professional Experience

### Tata Consultancy Services | IT Analyst *(Apr 2018 â€“ Dec 2019)*  
- Developed **Java modules** for trade, location movement, and settlement.  
- Designed SQL queries and stored procedures for high-volume data processing.  
- Collaborated in Agile environment to deliver reliable modules under tight deadlines.

### Capgemini | Associate Consultant *(Nov 2013 â€“ Mar 2018)*  
- Built **RESTful Java services** and microservices for turbine outage data.  
- Delivered production support ensuring smooth operations.  
- Adhered to coding standards, improved maintainability.

---

##  Contact & Profiles

- **GitHub:** [https://github.com/sarayusd]( https://github.com/sarayusd)  
- **LinkedIn:** [https://www.linkedin.com/in/sarayusd/](https://www.linkedin.com/in/sarayusd/)  
- **Email:** sarayusd31@gmail.com  

---

